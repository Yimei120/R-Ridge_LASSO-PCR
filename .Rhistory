nrow(data_test)
?sample
install.packages(c("glmnet", "leaps", "pls"))
?predict
?rnorm
knitr::opts_chunk$set(echo = TRUE)
if(!require(ISLR)) { install.packages("ISLR", repos = "http://cran.us.r-project.org"); library(ISLR) }
if(!require(leaps)) { install.packages("leaps", repos = "http://cran.us.r-project.org"); library(leaps) }
if(!require(glmnet)) { install.packages("glmnet", repos = "http://cran.us.r-project.org"); library(glmnet) }
if(!require(pls)) { install.packages("pls", repos = "http://cran.us.r-project.org"); library(pls) }
set.seed(1)
X = rnorm(200)
e = rnorm(200)
knitr::opts_chunk$set(echo = TRUE)
if(!require(ISLR)) { install.packages("ISLR", repos = "http://cran.us.r-project.org"); library(ISLR) }
if(!require(leaps)) { install.packages("leaps", repos = "http://cran.us.r-project.org"); library(leaps) }
if(!require(glmnet)) { install.packages("glmnet", repos = "http://cran.us.r-project.org"); library(glmnet) }
if(!require(pls)) { install.packages("pls", repos = "http://cran.us.r-project.org"); library(pls) }
?sample
```{r}
b0 = 4;b1 = 3;b2 = -2;b3 = 0.5
y = b0 + b1x + b2x^2 + b3x^3 + e
b0 = 4;b1 = 3;b2 = -2;b3 = 0.5
y = b0 + b1*x + b2*x^2 + b3*x^3 + e
train = sample(1:x,100,replace = TRUE)
test = (-train)
train_set = y[train]
test_set = y[test]
b0 = 4;b1 = 3;b2 = -2;b3 = 0.5
y = b0 + b1*X + b2*X^2 + b3*X^3 + e
train = sample(1:X,100,replace = TRUE)
test = (-train)
train_set = y[train]
test_set = y[test]
b0 = 4;b1 = 3;b2 = -2;b3 = 0.5
y = b0 + b1*X + b2*X^2 + b3*X^3 + e
set.seed(1)
train = sample(1:length(X),100,replace = TRUE)
test = (-train)
train_set = y[train]
test_set = y[test]
test_set
train_set
x.new = x
for(i in 2:10){
x.new = cbind(x.new,x^i)
}
colnames(x.new) = paste('x',1:ncol(x.new),sep = ' ')
data = data.frame(cbind(y,x.new))
regfit = regsubsets(y~.,data = data, nvmax = 10)
summary(regfit)
x.new = x
for(i in 2:10){
x.new = cbind(x.new,x^i)
}
colnames(x.new) = paste('x',1:ncol(x.new),sep = ' ')
data = data.frame(cbind(y,x.new))
regfit = regsubsets(y~.,data = data, nvmax = 10)
regfit.summary = summary(regfit)
plot(regfit.summary$rsq,xlab = "number of variables", ylab = 'R-squared',type = 'l')
x.new = x
for(i in 2:10){
x.new = cbind(x.new,x^i)
}
colnames(x.new) = paste('x',1:ncol(x.new),sep = ' ')
data = data.frame(cbind(y,x.new))
regfit = regsubsets(y~.,data = data, nvmax = 10)
regfit.summary = summary(regfit)
par(mfrow = c(2,2))
plot(regfit.summary$rsq,xlab = "number of variables", ylab = 'R-squared',type = 'l')
plot(regfit.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
plot(regfit.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
plot(regfit.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
?points
plot(regfit.summary$rsq,xlab = "number of variables", ylab = 'R-squared',type = 'l')
points(which.min(regfit.summary$rsq),regfit.summary$rsq[which.min(regfit.summary$rsq)],col = 'grey',cex = 2,pch = 20)
par(mfrow = c(2,2))
plot(regfit.summary$rsq,xlab = "number of variables", ylab = 'R-squared',type = 'l')
points(which.max(regfit.summary$rsq),regfit.summary$rsq[which.max(regfit.summary$rsq)],col = 'grey',cex = 2,pch = 20)
plot(regfit.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
points(which.max(regfit.summary$adjr2),regfit.summary$adjr2[which.max(regfit.summary$adjr2)],col = 'red',cex = 2,pch = 20)
plot(regfit.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
points(which.min(regfit.summary$bic),regfit.summary$bic[which.min(regfit.summary$bic)],col = 'green',cex = 2,pch = 20)
plot(regfit.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
points(which.min(regfit.summary$cp),regfit.summary$cp[which.min(regfit.summary$cp)],col = 'orange',cex = 2,pch = 20)
par(mfrow = c(2,2))
plot(regfit.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
points(which.max(regfit.summary$adjr2),regfit.summary$adjr2[which.max(regfit.summary$adjr2)],col = 'red',cex = 2,pch = 20)
which.max(regfit.summary$adjr2)
plot(regfit.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
points(which.min(regfit.summary$bic),regfit.summary$bic[which.min(regfit.summary$bic)],col = 'green',cex = 2,pch = 20)
which.min(regfit.summary$bic)
plot(regfit.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
points(which.min(regfit.summary$cp),regfit.summary$cp[which.min(regfit.summary$cp)],col = 'orange',cex = 2,pch = 20)
which.min(regfit.summary$cp)
coef(regfit,1)
set.seed(1)
X = rnorm(200)
e = rnorm(200)
b0 = 4;b1 = 3;b2 = -2;b3 = 0.5
y = b0 + b1*X + b2*X^2 + b3*X^3 + e
set.seed(1)
train = sample(1:length(X),100,replace = TRUE)
test = (-train)
train_set = y[train]
test_set = y[test]
trainset = data[train,]
testset = data[test,]
x.new = x
for(i in 2:10){
x.new = cbind(x.new,x^i)
}
colnames(x.new) = paste('x',1:ncol(x.new),sep = ' ')
data = data.frame(cbind(y,x.new))
trainset = data[train,]
testset = data[test,]
regfit = regsubsets(y~.,data = trainset, nvmax = 10)
regfit.summary = summary(regfit)
par(mfrow = c(2,2))
plot(regfit.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
points(which.max(regfit.summary$adjr2),regfit.summary$adjr2[which.max(regfit.summary$adjr2)],col = 'red',cex = 2,pch = 20)
which.max(regfit.summary$adjr2)
plot(regfit.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
points(which.min(regfit.summary$bic),regfit.summary$bic[which.min(regfit.summary$bic)],col = 'green',cex = 2,pch = 20)
which.min(regfit.summary$bic)
plot(regfit.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
points(which.min(regfit.summary$cp),regfit.summary$cp[which.min(regfit.summary$cp)],col = 'orange',cex = 2,pch = 20)
which.min(regfit.summary$cp)
#it shows that model with one feature is the best model.
coef(regfit,1)
regfit.full = regsubsets(y~.,data = data, nvmax = 1)
regfit.full.summary = summary(regfit.full)
regfit.full.summary
coef(regfit.full,1)
#it shows that model with one feature is the best model.
coef(regfit,1)
coefi = coef(regfit.full,1)
test.mat = model.matrix(y~.,data = testset)
pred = test.mat[,names(coefi)]%*%coefi
coefi = coef(regfit.full,1)
test.mat = model.matrix(y~.,data = testset)
pred = test.mat[,names(coefi)]%*%coefi
val.error = mean((data$y[testset] - pred)^2)
#calculate test error
coefi = coef(regfit.full,1)
#calculate test error
coef(regfit.full,1)
data[x.3]
data[,x3]
data
data[,x.3]
regfit.full = regsubsets(y~.,data = data, nvmax = 1)
regfit.full.summary = summary(regfit.full)
regfit.full.summary
coef(regfit.full,1)
test.mat
test.mat = data.matrix(y~.,data = testset)
testset = data[test,]
#calculate test error
test.mat = data.matrix(y~.,data = testset)
#calculate test error
test.mat = data.matrix(y~., testset)
test.mat = data.matrix(y~., data = data[test,] )
test.mat
test.mat = data.matrix(y~., data = data[test,] )
#calculate test error
test.mat = data.matrix(y~., data = data[test,] ,...)
#calculate test error
test.mat = data.matrix(y~., data = dta[test,])
x.new = x
for(i in 2:10){
x.new = cbind(x.new,x^i)
}
colnames(x.new) = paste('x',1:ncol(x.new),sep = ' ')
dta = data.frame(cbind(y,x.new))
trainset = dta[train,]
testset = dta[test,]
regfit = regsubsets(y~.,data = trainset, nvmax = 10)
regfit.summary = summary(regfit)
par(mfrow = c(2,2))
plot(regfit.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
points(which.max(regfit.summary$adjr2),regfit.summary$adjr2[which.max(regfit.summary$adjr2)],col = 'red',cex = 2,pch = 20)
which.max(regfit.summary$adjr2)
plot(regfit.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
points(which.min(regfit.summary$bic),regfit.summary$bic[which.min(regfit.summary$bic)],col = 'green',cex = 2,pch = 20)
which.min(regfit.summary$bic)
plot(regfit.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
points(which.min(regfit.summary$cp),regfit.summary$cp[which.min(regfit.summary$cp)],col = 'orange',cex = 2,pch = 20)
which.min(regfit.summary$cp)
#it shows that model with one feature is the best model.
coef(regfit,1)# It shows x.4 will be the best variable, and coefficient is -0.2036692, and intercept is 2.7306001.
#then fit model with the full dataset.
regfit.full = regsubsets(y~.,data = dta, nvmax = 1)
regfit.full.summary = summary(regfit.full)
coef(regfit.full,1)
#It shows x.3 will ve the best variable, and c
#calculate test error
test.mat = data.matrix(y~., data = dta[test,])
b0 = 4;b1 = 3;b2 = -2;b3 = 0.5
y = b0 + b1*X + b2*X^2 + b3*X^3 + e
set.seed(1)
train = sample(1:length(X),100,replace = TRUE)
test = (-train)
train_set = y[train]
test_set = y[test]
#calculate test error
test.mat = data.matrix(y~., data = dta[test,])
#calculate test error
test.mat = data.matrix(y~., data = dta[test,])
val.errors = rep(NA,10)
for(i in 1:10){
coefi = coef(regfit.full,i)
pred = test.mat[,names(coefi)]%*%coefi
errors[i] = mean((dta$y[test]-pred)^2)
}
errors = rep(NA,10)
for(i in 1:10){
coefi = coef(regfit.full,i)
pred = test.mat[,names(coefi)]%*%coefi
errors[i] = mean((dta$y[test]-pred)^2)
}
errors = rep(NA,10)
for(i in 1:10){
coefi = coef(regfit.full,i)
pred = test.mat[,names(coefi)]%*%coefi
errors[i] = mean((dta$y[test]-pred)^2)
}
#calculate test error
test.mat = data.matrix(y~., data = dta[test,])
?data.matrix
#calculate test error
test.mat = data.matrix(y~., dta[test,])
#calculate test error
test.mat = data.matrix(y~., testset)
#calculate test error
test.mat = model.matrix(y~., testset)
errors = rep(NA,10)
for(i in 1:10){
coefi = coef(regfit.full,i)
pred = test.mat[,names(coefi)]%*%coefi
errors[i] = mean((dta$y[test]-pred)^2)
}
errors = rep(NA,10)
for(i in 1:10){
coefi = coef(regfit.full,i)
pred = test.mat[,names(coefi)]%*%coefi
errors[i] = mean((dta$y[test]-pred)^2)
}
nrow(dta$y[test])
nrow(dta$y)
set.seed(1)
X = rnorm(200)
e = rnorm(200)
b0 = 4;b1 = 3;b2 = -2;b3 = 0.5
y = b0 + b1*X + b2*X^2 + b3*X^3 + e
nrow(dta$y)
dta
length(dta$y)
nrow(test.mat)
testset
trainset
train
test
train = sample(c(TRUE,FALSE),100,replace = TRUE)
test = (!train)
train_set = y[train]
test_set = y[test]
set.seed(1)
train = sample(c(TRUE,FALSE),100,replace = TRUE)
test = (!train)
train_set = y[train]
test_set = y[test]
train_set
test_set
x.new = x
for(i in 2:10){
x.new = cbind(x.new,x^i)
}
colnames(x.new) = paste('x',1:ncol(x.new),sep = ' ')
dta = data.frame(cbind(y,x.new))
trainset = dta[train,]
testset = dta[test,]
trainset
testset
set.seed(1)
X = rnorm(200)
e = rnorm(200)
b0 = 4;b1 = 3;b2 = -2;b3 = 0.5
y = b0 + b1*X + b2*X^2 + b3*X^3 + e
set.seed(1)
train = sample(c(TRUE,FALSE),100,replace = TRUE)
test = (!train)
train_set = y[train]
test_set = y[test]
x.new = x
for(i in 2:10){
x.new = cbind(x.new,x^i)
}
colnames(x.new) = paste('x',1:ncol(x.new),sep = ' ')
dta = data.frame(cbind(y,x.new))
trainset = dta[train,]
testset = dta[test,]
trainset
#calculate test error
test.mat = model.matrix(y~., testset)
errors = rep(NA,10)
for(i in 1:10){
coefi = coef(regfit.full,i)
pred = test.mat[,names(coefi)]%*%coefi
errors[i] = mean((dta$y[test]-pred)^2)
}
nrow(test.mat)
coefi = coef(regfit.full,1)
pred = test.mat[,names(coefi)]%*%coefi
errors = mean((dta$y[test]-pred)^2)
errors
regfit.fwd = regsubsets(y~.,data = trainset,nvmax = 10,method = 'forward')
fwd.summary = summary(regfit.fwd)
regfit.bwd = regsubsets(y~.,data = testset,nvmax = 10,method = 'backward')
bwd.summary = summary(regfit.bwd)
plot(fwd.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
points(which.max(fwd.summary$adjr2),fwd.summary$adjr2[which.max(fwd.summary$adjr2)],col = 'red',cex = 2,pch = 20)
which.max(fwd.summary$adjr2)
plot(fwd.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
points(which.min(fwd.summary$bic),fwd.summary$bic[which.min(fwd.summary$bic)],col = 'green',cex = 2,pch = 20)
which.min(fwd.summary$bic)
plot(fwd.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
points(which.min(fwd.summary$cp),fwd.summary$cp[which.min(fwd.summary$cp)],col = 'orange',cex = 2,pch = 20)
which.min(fwd.summary$cp)
par(mfrow = c(2,3))
#fwd
plot(fwd.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
points(which.max(fwd.summary$adjr2),fwd.summary$adjr2[which.max(fwd.summary$adjr2)],col = 'red',cex = 2,pch = 20)
which.max(fwd.summary$adjr2)
plot(fwd.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
points(which.min(fwd.summary$bic),fwd.summary$bic[which.min(fwd.summary$bic)],col = 'green',cex = 2,pch = 20)
which.min(fwd.summary$bic)
plot(fwd.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
points(which.min(fwd.summary$cp),fwd.summary$cp[which.min(fwd.summary$cp)],col = 'orange',cex = 2,pch = 20)
which.min(fwd.summary$cp)
plot(bwd.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
points(which.max(bwd.summary$adjr2),bwd.summary$adjr2[which.max(bwd.summary$adjr2)],col = 'red',cex = 2,pch = 20)
which.max(bwd.summary$adjr2)
plot(bwd.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
points(which.min(bwd.summary$bic),bwd.summary$bic[which.min(bwd.summary$bic)],col = 'green',cex = 2,pch = 20)
which.min(bwd.summary$bic)
plot(bwd.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
points(which.min(bwd.summary$cp),bwd.summary$cp[which.min(bwd.summary$cp)],col = 'orange',cex = 2,pch = 20)
which.min(bwd.summary$cp)
par(mfrow = c(2,3))
#fwd
plot(fwd.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
points(which.max(fwd.summary$adjr2),fwd.summary$adjr2[which.max(fwd.summary$adjr2)],col = 'red',cex = 2,pch = 20)
which.max(fwd.summary$adjr2)
plot(fwd.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
points(which.min(fwd.summary$bic),fwd.summary$bic[which.min(fwd.summary$bic)],col = 'green',cex = 2,pch = 20)
which.min(fwd.summary$bic)
plot(fwd.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
points(which.min(fwd.summary$cp),fwd.summary$cp[which.min(fwd.summary$cp)],col = 'orange',cex = 2,pch = 20)
which.min(fwd.summary$cp)
#bwd
plot(bwd.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
points(which.max(bwd.summary$adjr2),bwd.summary$adjr2[which.max(bwd.summary$adjr2)],col = 'red',cex = 2,pch = 20)
which.max(bwd.summary$adjr2)
plot(bwd.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
points(which.min(bwd.summary$bic),bwd.summary$bic[which.min(bwd.summary$bic)],col = 'green',cex = 2,pch = 20)
which.min(bwd.summary$bic)
plot(bwd.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
points(which.min(bwd.summary$cp),bwd.summary$cp[which.min(bwd.summary$cp)],col = 'orange',cex = 2,pch = 20)
which.min(bwd.summary$cp)
regfit.fwd = regsubsets(y~.,data = trainset,nvmax = 10,method = 'forward')
fwd.summary = summary(regfit.fwd)
regfit.bwd = regsubsets(y~.,data = trainset,nvmax = 10,method = 'backward')
bwd.summary = summary(regfit.bwd)
par(mfrow = c(2,3))
#fwd
plot(fwd.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
points(which.max(fwd.summary$adjr2),fwd.summary$adjr2[which.max(fwd.summary$adjr2)],col = 'red',cex = 2,pch = 20)
which.max(fwd.summary$adjr2)
plot(fwd.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
points(which.min(fwd.summary$bic),fwd.summary$bic[which.min(fwd.summary$bic)],col = 'green',cex = 2,pch = 20)
which.min(fwd.summary$bic)
plot(fwd.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
points(which.min(fwd.summary$cp),fwd.summary$cp[which.min(fwd.summary$cp)],col = 'orange',cex = 2,pch = 20)
which.min(fwd.summary$cp)
#bwd
plot(bwd.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
points(which.max(bwd.summary$adjr2),bwd.summary$adjr2[which.max(bwd.summary$adjr2)],col = 'red',cex = 2,pch = 20)
which.max(bwd.summary$adjr2)
plot(bwd.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
points(which.min(bwd.summary$bic),bwd.summary$bic[which.min(bwd.summary$bic)],col = 'green',cex = 2,pch = 20)
which.min(bwd.summary$bic)
plot(bwd.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
points(which.min(bwd.summary$cp),bwd.summary$cp[which.min(bwd.summary$cp)],col = 'orange',cex = 2,pch = 20)
which.min(bwd.summary$cp)
fwd.full1 = regsubsets(y~.,data = dta, nvmax = 1,method = 'forward')
coef(fwd.full,1)
fwd.full1 = regsubsets(y~.,data = dta, nvmax = 1,method = 'forward')
coef(fwd.full1,1)
fwd.full2 = regsubsets(y~.,data = dta,nvmax = 2,method = 'forward')
coef(fwd.full2,2)
# one feature
fwd.full1 = regsubsets(y~.,data = dta, nvmax = 1,method = 'forward')
coef(fwd.full1,1)
#two features
fwd.full2 = regsubsets(y~.,data = dta,nvmax = 2,method = 'forward')
coef(fwd.full2,2)
fwd.full2 = regsubsets(y~.,data = dta,nvmax = 2,method = 'forward')
coef(fwd.full2,2)
par(mfrow = c(2,3))
#fwd
plot(fwd.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
points(which.max(fwd.summary$adjr2),fwd.summary$adjr2[which.max(fwd.summary$adjr2)],col = 'red',cex = 2,pch = 20)
which.max(fwd.summary$adjr2)
plot(fwd.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
points(which.min(fwd.summary$bic),fwd.summary$bic[which.min(fwd.summary$bic)],col = 'green',cex = 2,pch = 20)
which.min(fwd.summary$bic)
plot(fwd.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
points(which.min(fwd.summary$cp),fwd.summary$cp[which.min(fwd.summary$cp)],col = 'orange',cex = 2,pch = 20)
which.min(fwd.summary$cp)
#bwd
plot(bwd.summary$adjr2,xlab =  "number of variables", ylab = 'adjusted R-squared',type = 'l')
points(which.max(bwd.summary$adjr2),bwd.summary$adjr2[which.max(bwd.summary$adjr2)],col = 'red',cex = 2,pch = 20)
which.max(bwd.summary$adjr2)
plot(bwd.summary$bic,xlab =  "number of variables",ylab = 'BIC',type = 'l')
points(which.min(bwd.summary$bic),bwd.summary$bic[which.min(bwd.summary$bic)],col = 'green',cex = 2,pch = 20)
which.min(bwd.summary$bic)
plot(bwd.summary$cp,xlab = 'number of variables',ylab = 'Cp',type = 'l')
points(which.min(bwd.summary$cp),bwd.summary$cp[which.min(bwd.summary$cp)],col = 'orange',cex = 2,pch = 20)
which.min(bwd.summary$cp)
fwd.full2 = regsubsets(y~.,data = dta,nvmax = 2,method = 'forward')
coef(fwd.full2,2)
#one feature
bwd.full1 = regsubsets(y~.,data = dta, nvmax = 1,method = 'backward')
coef(bwd.full1,1)
# two features
bwd.full2 = regsubsets(y~.,data = dta, nvmax = 2,method = 'backward')
coef(bwd.full2,2)
test.mat = model.matrix(y~., testset)
test.mat
test.mat = model.matrix(y~., testset)
#one feature forward
coefi = coef(fwd.full1,1)
pred = test.mat[,names(coefi)]%*%coefi
errors = mean((dta$y[test]-pred)^2)
errors
#two features forward
mean((dta$y[test]-test.mat[,names(coef(fwd.full2,2))]%*%coef(fwd.full2,2))^2)
#one feature backward
mean((dta$y[test]-test.mat[,names(coef(bwd.full1,1))]%*%coef(bwd.full1,1))^2)
# two features backward
mean((dta$y[test]-test.mat[,names(coef(bwd.full2,2))]%*%coef(bwd.full2,2))^2)
x = model.matrix(y~.,dta)[,-1]
x
x = model.matrix(y~.,dta)[,-1]
y = dta$y
?predict
x = model.matrix(y~.,dta)[,-1]
y = dta$y
grid = 10^seq(10,-2,length = 100)
lasso = glmnet(x[train,],y[train],alpha = 1,lambda = grid)
summary(lasso)
x = model.matrix(y~.,dta)[,-1]
y = dta$y
grid = 10^seq(10,-2,length = 100)
lasso = glmnet(x,y,alpha = 1,lambda = grid)
summary(lasso)
set.seed(2)
cv.out = cv.glmnet(x[train,],y[train],alpha = 1)
plot(cv.out)
bestlam = which.min(cv.out$lambda)
bestlam = which.min(cv.out$lambda)
bestlam
x = model.matrix(y~.,dta)[,-1]
y = dta$y
grid = 10^seq(10,-2,length = 100)
lasso = glmnet(x[train,],y[train],alpha = 1,lambda = grid)
summary(lasso)
set.seed(2)
cv.out = cv.glmnet(x[train,],y[train],alpha = 1)
plot(cv.out)
bestlam = which.min(cv.out$lambda)
bestlam
lasso.predict = predict(lasso,s = bestlam,newx = x[test,])
mean((lasso.predict-y[test])^2)
lasso.predict = predict(lasso,s = bestlam,newx = x[test,])
mean((lasso.predict-y.test)^2)
lasso.predict = predict(lasso,s = bestlam,newx = x[test,])
mean((lasso.predict-y[test])^2)
lasso.coef = predict(full,type = 'coefficients',s = bestlam)
full = glmnet(x,y,alpha = 1,lambda = grid)
lasso.coef = predict(full,type = 'coefficients',s = bestlam)
lasso.coef
lasso.coef = predict(full,type = 'coefficients',s = bestlam)[1:10,]
lasso.coef
lasso.coef
x = model.matrix(y~.,dta)[,-1]
y = dta$y
#grid = 10^seq(10,-2,length = 100)
lasso = glmnet(x[train,],y[train],alpha = 1)
summary(lasso)
set.seed(2)
cv.out = cv.glmnet(x[train,],y[train],alpha = 1)
plot(cv.out)
bestlam = which.min(cv.out$lambda)
bestlam
lasso.predict = predict(lasso,s = bestlam,newx = x[test,])
mean((lasso.predict-y[test])^2)
#the test error is 14.38783
full = glmnet(x,y,alpha = 1)
lasso.coef = predict(full,type = 'coefficients',s = bestlam)[1:10,]
lasso.coef
